{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparkify Project Workspace\n",
    "This workspace contains a tiny subset (128MB) of the full dataset available (12GB). Feel free to use this workspace to build your project, or to explore a smaller subset with Spark before deploying your cluster on the cloud. Instructions for setting up your Spark cluster is included in the last lesson of the Extracurricular Spark Course content.\n",
    "\n",
    "You can follow the steps below to guide your data analysis and model building portion of this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import avg, col, concat, desc, explode, lit, min, max, split, udf, isnull\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql import Window\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier,LinearSVC, GBTClassifier, DecisionTreeClassifier, NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import CountVectorizer, IDF, Normalizer, PCA, RegexTokenizer, StandardScaler, StopWordsRemover, StringIndexer, VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a Spark session\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Sparkify\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Clean Dataset\n",
    "In this workspace, the mini-dataset file is `mini_sparkify_event_data.json`. Load and clean the dataset, checking for invalid or missing data - for example, records without userids or sessionids. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Steps\n",
    "\n",
    "I will perform below steps in the preprocessing part to discover and analyze the dataset in a better way. \n",
    "\n",
    "1. Loading the data from json file and make transformation to pandas dataframe.\n",
    "2. Dealing with missing variables.\n",
    "    1. Analyzing the variables of columns and removing empty entries, '', in userID.   \n",
    "    2. Identifying the missing features and removing or replacing them.\n",
    "3. Converting the timestamp column in more readible way. \n",
    "4. Converting gender information to binary variable from Female to Male. \n",
    "\n",
    "After performing these steps, *Churn* will be defined according to Cancellation Confirmation feature. In the Churn column, 1 will represent the user has churned and 0 otherwise. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist: string (nullable = true)\n",
      " |-- auth: string (nullable = true)\n",
      " |-- firstName: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- itemInSession: long (nullable = true)\n",
      " |-- lastName: string (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- method: string (nullable = true)\n",
      " |-- page: string (nullable = true)\n",
      " |-- registration: long (nullable = true)\n",
      " |-- sessionId: long (nullable = true)\n",
      " |-- song: string (nullable = true)\n",
      " |-- status: long (nullable = true)\n",
      " |-- ts: long (nullable = true)\n",
      " |-- userAgent: string (nullable = true)\n",
      " |-- userId: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_path = 'mini_sparkify_event_data.json'\n",
    "df = spark.read.json(data_path)\n",
    "# df.persist()\n",
    "# See the frame schema\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since I am more familiar with pandas dataframe, I will convert the spark object to pandas df.\n",
    "\n",
    "[1] https://stackoverflow.com/questions/29226210/what-is-the-spark-dataframe-method-topandas-actually-doing\n",
    "\n",
    "[2] https://www.oreilly.com/library/view/pyspark-cookbook/9781788835367/fe13b699-9b45-4295-a0cb-6375fa98a3e3.xhtml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pandas = df.toPandas()\n",
    "df_pandas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To know nulls\n",
    "df_pandas.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dealing With Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before proceeding the data cleaning, lets see the NaN values in the dataset columns.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pandas.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(how = 'any', subset = ['userId', 'sessionId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select('userId').dropDuplicates().sort('userId').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pandas = df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pandas.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is seen that *FirstName, Gender, LastName, Location, Registration, and UserAgent* have the same number of missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pandas['auth'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pandas['gender'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is seen that we have None values in gender section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pandas['level'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pandas['method'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pandas['page'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_pandas['registration'].unique()\n",
    "df_pandas['status'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pandas['userId'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is seen that we have **' '** value as an entry in the dataset. So we can clear them first and then check the None values in the gender section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pandas[df_pandas['userId'] == '']['userId'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets check the count in the spark dataframe.\n",
    "\n",
    "[1] https://docs.databricks.com/spark/latest/dataframes-datasets/introduction-to-dataframes-python.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter(df.userId == '').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step will be removing the **' '** values in UserId. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.filter(df.userId != '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter(df.userId == '').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pandas = df.toPandas()\n",
    "df_pandas.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's observe the missing values after the conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pandas[df_pandas.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we will make analysis based on Chunk, it is not needed to drop the None values in artist, length, and song column. Because, they indicate that user is logged in but not listening any song yet therefore no length value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Unique values in auth  column : \\n{}'.format(df_pandas['auth'].unique()))\n",
    "print('Unique values in gender  column : \\n{}'.format(df_pandas['gender'].unique()))\n",
    "print('Unique values in level  column : \\n{}'.format(df_pandas['level'].unique()))\n",
    "print('Unique values in method  column : \\n{}'.format(df_pandas['method'].unique()))\n",
    "print('Unique values in page  column : \\n{}'.format(df_pandas['page'].unique()))\n",
    "print('Unique values in status  column : \\n{}'.format(df_pandas['status'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is seen that after dropping the ' ' values in UserId column, we also clean the FirstName, Gender, LastName, Location, Registration, and UserAgent columns which have the same missing number count as UserId ' ' count."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we compare the unique values in dataset before and after the cleaning of UserId column, it is seen that we have lost two information in the auth column, Logged out and Guest. Additionaly, in the page column, we do not have Login, Registration, and Submit Registration informations anymore. \n",
    "\n",
    "Since we have dropped the *empty* user ıds, it might be logical in the sense of users without userid can be guests or logged out users. It make sense for page column also because the lost informations are related to guest users and logged out users.\n",
    "\n",
    "It is also logical that we have lost None values in gender column, because guest users or logged out users do not have gender information. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting The Timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Timestamp.html\n",
    "\n",
    "[2] https://stackoverflow.com/questions/13890935/does-pythons-time-time-return-the-local-or-utc-timestamp\n",
    "\n",
    "[3] https://stackoverflow.com/questions/2265357/parse-date-string-and-change-format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pandas['ts'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_time = udf(lambda x: datetime.datetime.fromtimestamp(x / 1000.0).strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "df = df.withColumn(\"time\", get_time(df.ts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use Python function in Spark, I have used udf.\n",
    "\n",
    "[1] https://changhsinlee.com/pyspark-udf/\n",
    "\n",
    "[2] https://docs.databricks.com/spark/latest/spark-sql/udf-python.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pandas = df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_pandas.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the registration column is also in timestamp format, I will perform the same conversion of ts column for registration column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('registration_time', get_time(df.registration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pandas = df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pandas.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "When you're working with the full dataset, perform EDA by loading a small subset of the data and doing basic manipulations within Spark. In this workspace, you are already provided a small subset of data you can explore.\n",
    "\n",
    "### Define Churn\n",
    "\n",
    "Once you've done some preliminary analysis, create a column `Churn` to use as the label for your model. I suggest using the `Cancellation Confirmation` events to define your churn, which happen for both paid and free users. As a bonus task, you can also look into the `Downgrade` events.\n",
    "\n",
    "Customer churn occurs when customers/subscribers stop doing business with a company or service. We can define a user as churned if there is an Cancellation Confirmation event. And Churn is defined both free and paid users. In order to track the downgrade event of a paid user can also be sight about customer churn.\n",
    "\n",
    "\n",
    "[1] https://blog.recurly.com/better-way-to-calculate-your-churn-rate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First look for cancellation confirmation events to define Churn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create churn label\n",
    "flag_cancellation = udf(lambda x: 1 if x == 'Cancellation Confirmation' else 0, IntegerType())\n",
    "\n",
    "# Apply it to the dataframe\n",
    "df = df.withColumn('churn', flag_cancellation('page'))\n",
    "\n",
    "# label user who churned\n",
    "windowval = Window.partitionBy('userId')\n",
    "\n",
    "# Apply it to the dataframe\n",
    "df = df.withColumn('churn', max('churn').over(windowval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pandas = df.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, look for downgrade events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create downgrade label\n",
    "flag_downgrade = udf(lambda x: 1 if x == \"Submit Downgrade\" else 0, IntegerType())\n",
    "\n",
    "# Apply it to the dataframe\n",
    "df = df.withColumn(\"downgrade\", flag_downgrade(\"page\"))\n",
    "\n",
    "# label user who've ever downgraded\n",
    "windowval = Window.partitionBy('userId')\n",
    "\n",
    "# Apply it to the dataframe\n",
    "df = df.withColumn('downgrade', max('downgrade').over(windowval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pandas = df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pandas.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's observe the spark dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select('userId').dropDuplicates().sort('userId').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(['userId', 'churn', 'downgrade']).dropDuplicates().show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have defined **churn** and **downgrade** events as seperate columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Explore Data\n",
    "Once you've defined churn, perform some exploratory data analysis to observe the behavior for users who stayed vs users who churned. You can start by exploring aggregates on these two groups of users, observing how much of a specific action they experienced per a certain time unit or number of songs played."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gender distribution on churn event\n",
    "\n",
    "First, we can explore the gender distribution on churn event to understand gender has an effect or not.\n",
    "\n",
    "[1] https://medium.com/@andykashyap/top-5-tricks-to-make-plots-look-better-9f6e687c1e08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropDuplicates([\"userId\", \"gender\"]).groupby([\"churn\", \"gender\"]).count().sort(\"churn\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pandas_gender = df.dropDuplicates([\"userId\", \"gender\"]).groupby([\"churn\", \"gender\"]).count().sort(\"churn\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "ax = sns.barplot(x = 'churn', y = 'count', hue = 'gender', data = df_pandas_gender,  palette = \"Blues_d\")\n",
    "plt.xlabel('Churn', fontsize = 14)\n",
    "plt.ylabel('Count', fontsize = 14)\n",
    "plt.legend(title = 'Gender', loc = 'best', ncol = 2)\n",
    "\n",
    "plot = plt.title('Gender Distribution of Churn Event', fontsize = 14)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is seen that male customers are slightly like to be churn than the female users. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Number of played/listened songs\n",
    "\n",
    "It might be a good indicator to understand the number of played songs in a session among the genders. Therefore, we may see the reason of male users have more likely to be churned.\n",
    "\n",
    "[1] https://www.datacamp.com/community/blog/seaborn-cheat-sheet-python\n",
    "\n",
    "[2] https://seaborn.pydata.org/generated/seaborn.violinplot.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pandas_song = df.where('page == \"NextSong\"').groupby(['churn', 'userId', 'sessionId','gender']).count()\\\n",
    "    .groupby(['churn', 'userId', 'gender']).agg({'count':'avg'})\\\n",
    "    .withColumnRenamed('avg(count)', 'avg_songs_played')\\\n",
    "    .toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "ax = sns.violinplot('churn', y = 'avg_songs_played', hue = 'gender', data = df_pandas_song, palette=\"Set2\", split = True, inner=\"quartile\")\n",
    "plt.xlabel('churn', fontsize = 12)\n",
    "plt.ylabel('Average count of listened songs per session', fontsize = 12)\n",
    "plt.legend(title = 'Gender', loc = 'best', ncol = 2)\n",
    "plt.title('Listened music distribution among gender')\n",
    "sns.despine(ax=ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is seen that churned users had listened less music than the others. And also churned female users average listened songs are more than males. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Notes on Violin Plot\n",
    "\n",
    "A violin plot plays a similar role as a box and whisker plot. It shows the distribution of quantitative data across several levels of one (or more) categorical variables such that those distributions can be compared. Unlike a box plot, in which all of the plot components correspond to actual datapoints, the violin plot features a kernel density estimation of the underlying distribution.\n",
    "\n",
    "Violin plots have many of the same summary statistics as box plots:\n",
    "* The white dot represents the median\n",
    "* The thick gray bar in the center represents the interquartile range\n",
    "* The thin gray line represents the rest of the distribution, except for points that are determined to be “outliers” using a method that is a function of the interquartile range.\n",
    "\n",
    "On each side of the gray line is a kernel density estimation to show the distribution shape of the data. Wider sections of the violin plot represent a higher probability that members of the population will take on the given value; the skinnier sections represent a lower probability.\n",
    "\n",
    "[1] https://mode.com/blog/violin-plot-examples\n",
    "\n",
    "[2] https://blog.bioturing.com/2018/05/16/5-reasons-you-should-use-a-violin-graph/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pandas_likes = df.where('page == \"NextSong\" OR page == \"Thumbs Up\"').groupby(['userId', 'churn', 'gender', 'page']).count().toPandas()\n",
    "df_pandas_likes = df_pandas_likes.pivot_table(index=['userId','churn','gender'], values='count', columns='page').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "ax = sns.violinplot(data = df_pandas_likes, x = 'churn', y = 'NextSong', hue = 'gender', split = True,  inner = \"quartile\", palette=\"Set2\")\n",
    "plt.xlabel('Churn Event')\n",
    "plt.ylabel('Played songs count according to NextSong Event')\n",
    "plt.legend(title = 'Gender', loc = 'best')\n",
    "title = plt.title('Total listening song distribution effect on churn by gender')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the mean of the total listened songs do not change that much among churned and unchurned users. However, we can say that female users have larger mean value and distribution than the male users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "ax = sns.violinplot(data = df_pandas_likes, x = 'churn', y = 'Thumbs Up', hue = 'gender', split = True,  inner = \"quartile\", palette=\"Set3\")\n",
    "plt.xlabel('Churn event')\n",
    "plt.ylabel('Liked song count according to ThumbsUp event')\n",
    "plt.legend(title='Gender', loc='best')\n",
    "title = plt.title('Total liked song distribution effect on churn by gender')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also for the liked song distribution, churned and normal users have similar characteristics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Churned user status\n",
    "\n",
    "It might me a good indicator to see which payment status of user had churned most."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pandas_level = df.filter('page == \"Cancellation Confirmation\"').groupby('level').count().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "ax = sns.barplot(data = df_pandas_level, x = 'level', y = 'count', palette=\"Set1\")\n",
    "plt.xlabel('Payment level', fontsize = 12)\n",
    "plt.ylabel('')\n",
    "plt.title('Churned user payment level distribution', fontsize = 14)\n",
    "sns.despine(ax=ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is seen that paid users had churned more than free users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Page distribution\n",
    "\n",
    "Let see the page distribution of churned and current users to understand the differences between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churned_user = df_pandas[df_pandas.churn == 1].groupby(['page'])['userId'].count()\n",
    "churned_user = churned_user /churned_user.sum()*100\n",
    "\n",
    "active_user = df_pandas[df_pandas.churn == 0].groupby(['page'])['userId'].count()\n",
    "active_user = active_user /active_user.sum()*100\n",
    "\n",
    "users_df = pd.DataFrame({'Cancelled': churned_user,'Active users':active_user})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = users_df.plot(kind='barh', figsize=(12,10), cmap = \"plasma\");\n",
    "ax.set_xlabel('Percent of envent occurence (%)')\n",
    "ax.set_title('Percent of envent occurence for active and cancelled users');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since Next Song creates a bias in the figure, I have decided to drop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churned_user = df_pandas[df_pandas.churn == 1].groupby(['page'])['userId'].count().drop('NextSong')\n",
    "# Define percentage to visualize better\n",
    "churned_user = churned_user /churned_user.sum()*100\n",
    "\n",
    "active_user = df_pandas[df_pandas.churn == 0].groupby(['page'])['userId'].count().drop('NextSong')\n",
    "# Define percentage to visualize better\n",
    "active_user = active_user /active_user.sum()*100\n",
    "\n",
    "users_df = pd.DataFrame({'Cancelled': churned_user,'Active users':active_user})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = users_df.plot(kind='barh', figsize=(12,10), cmap = \"plasma\");\n",
    "ax.set_xlabel('Percentage of envent occurence (%)')\n",
    "ax.set_title('Percentage distribution of page events among the active and cancelled users ');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Membership duration\n",
    "\n",
    "Lastly, we can investigate the membership duration of users to see effect on churn event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pandas_lifetime = df\\\n",
    "    .select('userId','registration','ts','churn') \\\n",
    "    .withColumn('lifetime',(df.ts-df.registration)) \\\n",
    "    .groupBy('userId','churn') \\\n",
    "    .agg({'lifetime':'max'}) \\\n",
    "    .withColumnRenamed('max(lifetime)','lifetime') \\\n",
    "    .select('userId', 'churn', (col('lifetime')/1000/3600/24).alias('lifetime')) \\\n",
    "    .toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(data = df_pandas_lifetime, y = 'churn', x = 'lifetime', orient = 'h', palette = \"Set2\")\n",
    "plt.xlabel('Days since registration when churn')\n",
    "plt.ylabel('Has customer churned')\n",
    "title = plt.title('Churned customer use the service for a shorter period of time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "Once you've familiarized yourself with the data, build out the features you find promising to train your model on. To work with the full dataset, you can follow the following steps.\n",
    "- Write a script to extract the necessary features from the smaller subset of data\n",
    "- Ensure that your script is scalable, using the best practices discussed in Lesson 3\n",
    "- Try your script on the full data set, debugging your script if necessary\n",
    "\n",
    "If you are working in the classroom workspace, you can just extract features based on the small subset of data contained here. Be sure to transfer over this work to the larger dataset when you work on your Spark cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Dataset Features:\n",
    "In the dataset, we have below features:\n",
    "\n",
    "<u>Categorical features</u>\n",
    "* Currently listening artists\n",
    "* Authorization\n",
    "* First/Last name of user\n",
    "* Gender of user\n",
    "* The payment level of membership (Paid/Free)\n",
    "* Location\n",
    "* Method\n",
    "* Current page\n",
    "* Currently listening song\n",
    "* User agent, (MacOs, Windows, etc.)\n",
    "\n",
    "<u>Numerical features</u>\n",
    "* Item in session\n",
    "* Length\n",
    "* Registration date in timestamp format\n",
    "* SessionId\n",
    "* Status\n",
    "* Time as ts in timestamp format\n",
    "* Userid\n",
    "\n",
    "\n",
    "For the analysis, we will add the below features according to the data exploration that we have performed in the previous section.\n",
    "\n",
    "1. Gender feature as numerical/binary variable\n",
    "2. Number of played/listened songs\n",
    "3. Number of liked songs according to thumbs up/down\n",
    "4. Number of songs added to playlist\n",
    "5. Number of songs listened per session\n",
    "6. Number of listened artists\n",
    "7. Number of added friends.\n",
    "8. Total time duration/lenght of listening event\n",
    "9. Membership duration\n",
    "10. Churn label\n",
    "11. Downgrade label\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gender feature as numerical/binary variable\n",
    "feature_1 = df.select(\"userId\", \"gender\").dropDuplicates().replace(['M', 'F'], ['0', '1'], 'gender').select('userId', col('gender').cast('int'))\n",
    "feature_1.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of played/listened songs\n",
    "feature_2 = df.select('userID','song').groupBy('userID').count().withColumnRenamed('count', 'total_songs')\n",
    "feature_2.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of liked songs according to thumbs up/down\n",
    "feature_3 = df.select('userID','page').where(df.page == 'Thumbs Up').groupBy('userID').count().withColumnRenamed('count', 'thumbs_up')\n",
    "feature_3.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of liked songs according to thumbs up/down\n",
    "feature_4 = df.select('userID','page').where(df.page == 'Thumbs Down').groupBy('userID').count().withColumnRenamed('count', 'thumbs_down')\n",
    "feature_4.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of songs added to playlist\n",
    "feature_5 = df.select('userID','page').where(df.page == 'Add to Playlist').groupBy('userID').count().withColumnRenamed('count', 'add_to_playlist')\n",
    "feature_5.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of songs listened per session\n",
    "feature_6 = df.where('page == \"NextSong\"').groupby(['userId', 'sessionId']).count().groupby(['userId']).agg({'count':'avg'}).withColumnRenamed('avg(count)', 'avg_songs_played')\n",
    "feature_6.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of listened artists\n",
    "feature_7 = df.filter(df.page==\"NextSong\").select(\"userId\", \"artist\").dropDuplicates().groupby(\"userId\").count().withColumnRenamed(\"count\", \"artist_count\")\n",
    "feature_7.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of added friends\n",
    "feature_8 = df.select('userID','page').where(df.page == 'Add Friend').groupBy('userID').count().withColumnRenamed('count', 'add_friend') \n",
    "feature_8.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total time duration/lenght of listening event\n",
    "feature_9 = df.select('userID','length').groupBy('userID').sum().withColumnRenamed('sum(length)', 'listen_time')\n",
    "feature_9.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membership duration\n",
    "feature_10 = df.select('userId','registration','ts').withColumn('lifetime',(df.ts-df.registration)).groupBy('userId') \\\n",
    "    .agg({'lifetime':'max'}).withColumnRenamed('max(lifetime)','lifetime').select('userId', (col('lifetime')/1000/3600/24).alias('lifetime'))\n",
    "feature_10.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Churn label\n",
    "churn_label = df.select('userId', col('churn').alias('label')).dropDuplicates()\n",
    "churn_label.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downgrade label\n",
    "downgrade_label = df.select('userId', col('downgrade').alias('downgrade_label')).dropDuplicates()\n",
    "downgrade_label.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = feature_1.join(feature_2,'userID','outer') \\\n",
    "    .join(feature_3,'userID','outer') \\\n",
    "    .join(feature_4,'userID','outer') \\\n",
    "    .join(feature_5,'userID','outer') \\\n",
    "    .join(feature_6,'userID','outer') \\\n",
    "    .join(feature_7,'userID','outer') \\\n",
    "    .join(feature_8,'userID','outer') \\\n",
    "    .join(feature_9,'userID','outer') \\\n",
    "    .join(feature_10,'userID','outer') \\\n",
    "    .join(churn_label,'userID','outer') \\\n",
    "    .join(downgrade_label,'userID','outer') \\\n",
    "    .drop('userID') \\\n",
    "    .fillna(0)\n",
    "\n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving as SPARK format\n",
    "data.write.save('SparkFile_5.CSV', format='csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pandas = data.toPandas()\n",
    "data_pandas.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pandas.to_csv('PandasFile_61.CSV', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "Split the full dataset into train, test, and validation sets. Test out several of the machine learning methods you learned. Evaluate the accuracy of the various models, tuning parameters as necessary. Determine your winning model based on test accuracy and report results on the validation set. Since the churned users are a fairly small subset, I suggest using F1 score as the metric to optimize. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Notes on F1 Score\n",
    "\n",
    "According to Wikipedia, F1 Score is defined as a weighted average of the precision and recall where an F1 score reached its best value at 1 and worst at 0. But first lets define the precision and recall:\n",
    "\n",
    "* The precision is the number of correct positive results divided by the number of all positive results. Precision talks about how precise/accurate your model is out of those predicted positive, how many of them are actual positive. Precision is a good measure to determine, when the costs of False Positive is high. For instance, email spam detection. In email spam detection, a false positive means that an email that is non-spam (actual negative) has been identified as spam (predicted spam). The email user might lose important emails if the precision is not high for the spam detection model.\n",
    "\n",
    "* The recall is the number of correct positive results divided by the number of positive results that should have been returned. Recall actually calculates how many of the Actual Positives our model capture through labeling it as Positive (True Positive). Applying the same understanding, we know that Recall shall be the model metric we use to select our best model when there is a high cost associated with False Negative.\n",
    "\n",
    "\n",
    "And accuracy is one of the more obvious metrics, it is the measure of all the correctly identified cases. It is most used when all the classes are equally important.\n",
    "\n",
    "F1 Score is defined as the harmonic mean of Precision and Recall and gives a better measure of the incorrectly classified cases than the Accuracy Metric. And the use case differences of accuracy and F1 Score can be summarized as below:\n",
    "\n",
    "1. Accuracy is used when the True Positives and True negatives are more important while F1-score is used when the False Negatives and False Positives are crucial\n",
    "\n",
    "2. Accuracy can be used when the class distribution is similar while F1-score is a better metric when there are imbalanced classes as in the above case.\n",
    "\n",
    "3. In most real-life classification problems, imbalanced class distribution exists and thus F1-score is a better metric to evaluate our model on.\n",
    "\n",
    "\n",
    "[1] https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9\n",
    "\n",
    "[2] https://adamyedidia.files.wordpress.com/2014/11/f_score.pdf\n",
    "\n",
    "[3] https://medium.com/analytics-vidhya/accuracy-vs-f1-score-6258237beca2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pandas.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the saved features as the inputs except the churn event, indicated as label. Because the churn label will be the feature that we want to predict by using the related features.\n",
    "\n",
    "After defining the features, we will create the feature vector and perform transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The input features are all features except the Churn Label and the output is the churn event.\n",
    "\n",
    "features_labels = ['gender', 'total_songs', 'thumbs_up', 'thumbs_down', 'add_to_playlist',\n",
    "                   'avg_songs_played', 'artist_count', 'add_friend', 'listen_time', 'lifetime', 'downgrade_label' ]\n",
    "\n",
    "# Define the vector assembler for all input columns\n",
    "features_vector  = VectorAssembler(inputCols = features_labels, outputCol = \"features\")\n",
    "\n",
    "input_data = features_vector.transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a next step, we will perform standardization. Standardization is performed because using these variables without standardization in effect gives the variable with the larger range a weight of 100 in the analysis. Typical data standardization procedures equalize the range and/or data variability. Therefore we standardize the features by taking off the mean and divided by the standard deviation of each feature.\n",
    "\n",
    "[1] https://spark.apache.org/docs/latest/ml-features\n",
    "\n",
    "[2] https://scikit-learn.org/stable/modules/preprocessing.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard scaler\n",
    "features_scaler = StandardScaler(inputCol = \"features\", outputCol=\"scaled_features\", withMean=True)\n",
    "features_scaler_fit = features_scaler.fit(input_data)\n",
    "scaled_inputs = features_scaler_fit.transform(input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After standardize our features, we can divide our dataset in to test, train, and validation. We can use randomSplit function to divide our dataset. \n",
    "\n",
    "RandomSplit is performing the randomly splits this DataFrame with the provided weights. When we perform random splitting we are splitting the data randomly to generate two sets: one to use during training of the ML algorithm (training set), and the second to check whether the training is working (test set). This is widely done and a very good idea, as it catches overfitting which otherwise can make it seem like you have a great ML solution when it's actually effectively just memorized the answer for each data point and can't interpolate or generalize.\n",
    "\n",
    "And one of the main problem is selecting the seed which is defined according to reference 4.\n",
    "\n",
    "[1] https://spark.apache.org/docs/2.2.0/api/python/pyspark.sql.html\n",
    "\n",
    "[2] https://stackoverflow.com/questions/40606456/randomsplit-dont-respect-specific-weights-pyspark\n",
    "\n",
    "[3] https://stackoverflow.com/questions/24857650/issue-understanding-splitting-data-in-scala-using-randomsplit-for-machine-lear\n",
    "\n",
    "[4] https://medium.com/@ODSC/properly-setting-the-random-seed-in-ml-experiments-not-as-simple-as-you-might-imagine-219969c84752"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "train, rest = scaled_inputs.randomSplit([0.8, 0.2], seed = 45)\n",
    "validation, test = rest.randomSplit([0.5, 0.5], seed = 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_base_all_1 = test.withColumn('prediction', lit(1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "print('Test set metrics:')\n",
    "print('Accuracy: {}'.format(evaluator.evaluate(results_base_all_1, {evaluator.metricName: \"accuracy\"})))\n",
    "print('F-1 Score:{}'.format(evaluator.evaluate(results_base_all_1, {evaluator.metricName: \"f1\"})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_base_all_0 = test.withColumn('prediction', lit(0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "print('Test set metrics:')\n",
    "print('Accuracy: {}'.format(evaluator.evaluate(results_base_all_0, {evaluator.metricName: \"accuracy\"})))\n",
    "print('F-1 Score:{}'.format(evaluator.evaluate(results_base_all_0, {evaluator.metricName: \"f1\"})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a next step, we will perform classification with different algorithms to observe the result. \n",
    "\n",
    "[1] https://spark.apache.org/docs/latest/ml-classification-regression.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gradient Boost and Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The idea of boosting came out of the idea of whether a weak learner can be modified to become better. A weak hypothesis or weak learner is defined as one whose performance is at least slightly better than random chance.\n",
    "Gradient Boost Trees is the modified and improved version of AdaBoost. \n",
    "\n",
    "AdaBoost, which is the abbreviation of the Adaptive Boosting, is the first practical boosting algorithm proposed by Freund and Schapire in 1996. AdaBoost is an algorithm for constructing a “strong” classifier as linear combination of “simple” “weak” classifier. In other words, the main working principle is to convert a set of weak classifiers into a strong one. Weak classifier is described as less than 50% error over any distribution and strong classifier is thresholded linear combination of the weak classifier outputs. AdaBoost works by weighting the observations, putting more weight on difficult to classify instances and less on those already handled well. New weak learners are added sequentially that focus their training on the more difficult patterns. Predictions are made by majority vote of the weak learners’ predictions, weighted by their individual accuracy. \n",
    "\n",
    "Gradient boosting involves three elements:\n",
    "* A loss function to be optimized. The loss function used depends on the type of problem being solved. It must be differentiable, but many standard loss functions are supported and you can define your own. For example, regression may use a squared error and classification may use logarithmic loss\n",
    "* A weak learner to make predictions. Decision trees are used as the weak learner in gradient boosting\n",
    "* An additive model to add weak learners to minimize the loss function. Trees are added one at a time, and existing trees in the model are not changed. A gradient descent procedure is used to minimize the loss when adding trees.\n",
    "\n",
    "GBT build trees one at a time, where each new tree helps to correct errors made by previously trained tree. A great application of GBM is anomaly detection in supervised learning settings where data is often highly unbalanced such as DNA sequences, credit card transactions or cybersecurity.\n",
    "\n",
    "The differences between the GBT and RF can be explained as Gradient boosting uses regression trees for prediction purpose where a random forest use decision tree. ... The random forest is easy to parallelize but boosted trees are hard to do. Random forests overfit a sample of the training data and then reduces the overfit by simple averaging the predictors. If you carefully tune parameters, gradient boosting can result in better performance than random forests. However, gradient boosting may not be a good choice if you have a lot of noise, as it can result in overfitting. They also tend to be harder to tune than random forests.\n",
    "\n",
    "[1] https://machinelearningmastery.com/gentle-introduction-gradient-boosting-algorithm-machine-learning/\n",
    "\n",
    "[2] https://medium.com/@aravanshad/gradient-boosting-versus-random-forest-cfa3fa8f0d80\n",
    "\n",
    "[3] https://www.datasciencecentral.com/profiles/blogs/decision-tree-vs-random-forest-vs-boosted-trees-explained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the GBT classifier\n",
    "gbt = GBTClassifier(maxIter = 10, seed = 45)\n",
    "\n",
    "# set evaluator\n",
    "f1_evaluator = MulticlassClassificationEvaluator(metricName='f1')\n",
    "\n",
    "# build paramGrid\n",
    "paramGrid = ParamGridBuilder().build()\n",
    "\n",
    "gbt_crossvalidation = CrossValidator(estimator = gbt,\n",
    "                                    estimatorParamMaps = paramGrid,\n",
    "                                    evaluator = f1_evaluator,\n",
    "                                    numFolds = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time()\n",
    "cvModel_gbt = gbt_crossvalidation.fit(train)\n",
    "end = time()\n",
    "cvModel_gbt.avgMetrics\n",
    "print('The training process took {} seconds'.format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt_result = cvModel_gbt.transform(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(predictionCol = \"prediction\")\n",
    "print('Gradient Boosted Trees Metrics:')\n",
    "print('Accuracy: {}'.format(evaluator.evaluate(gbt_result, {evaluator.metricName: \"accuracy\"})))\n",
    "print('F-1 Score:{}'.format(evaluator.evaluate(gbt_result, {evaluator.metricName: \"f1\"})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the random forest classifier\n",
    "randomforest = RandomForestClassifier()\n",
    "\n",
    "# set evaluator\n",
    "f1_evaluator = MulticlassClassificationEvaluator(metricName = 'f1')\n",
    "\n",
    "# build paramGrid\n",
    "paramGrid = ParamGridBuilder().build()\n",
    "\n",
    "randomforest_crossval = CrossValidator(estimator = randomforest,\n",
    "                              estimatorParamMaps = paramGrid,\n",
    "                              evaluator = f1_evaluator,\n",
    "                              numFolds = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time()\n",
    "cvModel_rf = randomforest_crossval.fit(train)\n",
    "end = time()\n",
    "cvModel_rf.avgMetrics\n",
    "print('The training process took {} seconds'.format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest_result = cvModel_rf.transform(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "print('Random Forest Metrics:')\n",
    "print('Accuracy: {}'.format(evaluator.evaluate(randomforest_result, {evaluator.metricName: \"accuracy\"})))\n",
    "print('F-1 Score:{}'.format(evaluator.evaluate(randomforest_result, {evaluator.metricName: \"f1\"})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Support Vector Machines\n",
    "The working principle of the support vector machines is to find or create the hyperplane in an N-dimensional space that distinctly classifies the data points. The dimension of the hyperplane is depending on the number of the features. Hyperplanes are basicly the desicion boundaries that helps the classification of the data such that data points which are locating at te different side of the hyperplane are classified as different classes. Support vector machines are commonly used in face detection, text and hypertext categorization, classification of images, bioinformatics and, handwriting recognition. One of the real world example is performed in the article \"Application of support vector machine modeling for prediction of common diseases: the case of diabetes and pre-diabetes\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize classifier\n",
    "svm = LinearSVC(maxIter = 10)\n",
    "\n",
    "# set evaluator\n",
    "f1_evaluator = MulticlassClassificationEvaluator(metricName='f1')\n",
    "\n",
    "# build paramGrid\n",
    "paramGrid = ParamGridBuilder().build()\n",
    "\n",
    "svm_crossval = CrossValidator(estimator=svm,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=f1_evaluator,\n",
    "                          numFolds=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time()\n",
    "cvModel_svm = svm_crossval.fit(train)\n",
    "end = time()\n",
    "cvModel_svm.avgMetrics\n",
    "print('The training process took {} seconds'.format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_result = cvModel_svm.transform(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "print('SVM Metrics:')\n",
    "print('Accuracy: {}'.format(evaluator.evaluate(svm_result, {evaluator.metricName: \"accuracy\"})))\n",
    "print('F-1 Score:{}'.format(evaluator.evaluate(svm_result, {evaluator.metricName: \"f1\"})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Decision Tree Classifier\n",
    "\n",
    "In decision analysis, one of the visual and explicit representation of decision and decision making procedure can be performed by using decision trees. The decision tree is using a tree-like model of decisions such that a flowchart like tree structure in which each node internal node denotes a test and each branch represents an outcome of the test and each leaf node holds a corresponding class label. Decision tree is the one of the most powerfull and popular tool for classification and prediction. Decision trees are commonly using in medical diagnosis, failure prediction, credit scroing and crime risk investigation. Several business analysis examples can be found but one of the widely used one is the detection of the raudulent Financial Statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "# set evaluator\n",
    "f1_evaluator = MulticlassClassificationEvaluator(metricName='f1')\n",
    "\n",
    "# build paramGrid\n",
    "paramGrid = ParamGridBuilder().build()\n",
    "\n",
    "dt_crossval = CrossValidator(estimator=dt,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=f1_evaluator,\n",
    "                          numFolds=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time()\n",
    "cvModel_dt = dt_crossval.fit(train)\n",
    "end = time()\n",
    "cvModel_dt.avgMetrics\n",
    "print('The training process took {} seconds'.format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_result = cvModel_dt.transform(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "print('SVM Metrics:')\n",
    "print('Accuracy: {}'.format(evaluator.evaluate(dt_result, {evaluator.metricName: \"accuracy\"})))\n",
    "print('F-1 Score:{}'.format(evaluator.evaluate(dt_result, {evaluator.metricName: \"f1\"})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model summary: \n",
    "The logistic regression model has a accuracy of: 0.735, and F1 score of:0.622, using 1047.5 seconds on our server.\n",
    "The gradient boosted trees model has a accuracy of: 0.776, and F1 score of: 0.756, using 1560.5 seconds on our server.\n",
    "The support vector machine model has a accuracy of: 0.735, and F1 score of: 0.622, using 1184.0 seconds on our server.\n",
    "The random forest model has a accuracy of: 0.776, and F1 score of: 0.708, using 1220.6 seconds on our server.\n",
    "Although we do care about time resources, but since the data size is still reletively small, and the performance difference is huge, we will prefer the model that perform the best. Therefore, we choose GBT model as our final used model and conduct a grid search to fine tune our model this time.\n",
    "\n",
    "In the future, we may instead implement random forest model for more time efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Steps\n",
    "Clean up your code, adding comments and renaming variables to make the code easier to read and maintain. Refer to the Spark Project Overview page and Data Scientist Capstone Project Rubric to make sure you are including all components of the capstone project and meet all expectations. Remember, this includes thorough documentation in a README file in a Github repository, as well as a web app or blog post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
